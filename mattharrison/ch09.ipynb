{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.experimental import (\n",
    "    enable_iterative_imputer,\n",
    ")\n",
    "from sklearn import (\n",
    "    ensemble,\n",
    "    impute,\n",
    "    model_selection,    \n",
    "    preprocessing,\n",
    "    tree,\n",
    ")\n",
    "\n",
    "url = (\n",
    "    \"http://biostat.mc.vanderbilt.edu/\"\n",
    "    \"wiki/pub/Main/DataSets/titanic3.xls\"\n",
    ")\n",
    "df = pd.read_excel(url)\n",
    "def tweak_titanic(df):\n",
    "    df = df.drop(\n",
    "        columns=[\n",
    "            \"name\",\n",
    "            \"ticket\",\n",
    "            \"home.dest\",\n",
    "            \"boat\",\n",
    "            \"body\",\n",
    "            \"cabin\",\n",
    "        ]\n",
    "    ).pipe(pd.get_dummies, drop_first=True)\n",
    "    return df\n",
    "def get_train_test_X_y(\n",
    "    df, y_col, size=0.3, std_cols=None\n",
    "):\n",
    "    y = df[y_col]\n",
    "    X = df.drop(columns=y_col)\n",
    "    X_train, X_test, y_train, y_test = model_selection.train_test_split(\n",
    "        X, y, test_size=size, random_state=42\n",
    "    )\n",
    "    cols = X.columns\n",
    "    num_cols = [\n",
    "        \"pclass\",\n",
    "        \"age\",\n",
    "        \"sibsp\",\n",
    "        \"parch\",\n",
    "        \"fare\",\n",
    "    ]\n",
    "    fi = impute.IterativeImputer()\n",
    "\n",
    "    fitted = fi.fit_transform(X_train[num_cols])\n",
    "    X_train = X_train.assign(**{c:fitted[:,i] for i, c in enumerate(num_cols)})\n",
    "    test_fit = fi.transform(X_test[num_cols])\n",
    "    X_test = X_test.assign(**{c:test_fit[:,i] for i, c in enumerate(num_cols)})\n",
    "    if std_cols:\n",
    "        std = preprocessing.StandardScaler()\n",
    "        fitted = std.fit_transform(X_train[std_cols])\n",
    "        X_train = X_train.assign(**{c:fitted[:,i] for i, c in enumerate(std_cols)})\n",
    "        test_fit = std.transform(X_test[std_cols])\n",
    "        X_test = X_test.assign(**{c:test_fit[:,i] for i, c in enumerate(std_cols)})\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "ti_df = tweak_titanic(df)\n",
    "std_cols = \"pclass,age,sibsp,fare\".split(\",\")\n",
    "X_train, X_test, y_train, y_test = get_train_test_X_y(\n",
    "    ti_df, \"survived\", std_cols=std_cols\n",
    ")\n",
    "\n",
    "X = pd.concat([X_train, X_test])\n",
    "y = pd.concat([y_train, y_test])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    809\n",
       "0    809\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[~mask]\n",
    "df_upsample = resample(\n",
    "    surv_df,\n",
    "    replace=True,\n",
    "    n_samples=len(death_df),\n",
    "    random_state=42,\n",
    ")\n",
    "df2 = pd.concat([death_df, df_upsample])\n",
    "df2.survived.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    809\n",
       "0    809\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import (\n",
    "    RandomOverSampler,\n",
    ")\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "X_ros, y_ros = ros.fit_sample(X, y)\n",
    "pd.Series(y_ros).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    500\n",
       "0    500\n",
       "Name: survived, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.utils import resample\n",
    "mask = df.survived == 1\n",
    "surv_df = df[mask]\n",
    "death_df = df[~mask]\n",
    "df_downsample = resample(\n",
    "    death_df,\n",
    "    replace=False,\n",
    "    n_samples=len(surv_df),\n",
    "    random_state=42,\n",
    ")\n",
    "df3 = pd.concat([surv_df, df_downsample])\n",
    "df3.survived.value_counts()"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
